# Estatística básica

## Teste T (de Student) para duas amostras independentes

### Background da análise

Uma das perguntas mais comum em estatística é saber se há diferença entre as médias de dois grupos ou tratamentos. Para responder esta pergunta, William Sealy Gosset, químico da cervejaria Guinness, em 1908 desenvolveu o Teste T que é uma estátistica que segue uma distribuição t de Student para rejeitar ou não uma hipótese nula de médias iguais entre os grupos. 

> $$ t = \frac{(\bar{X}_1 - \bar{X}_2)}{\sqrt{\frac{2S^2_p}{n}}}$$

Onde: 

* $\bar{X}$<sub>1</sub> -  $\bar{X}$<sub>2</sub> = diferença entre as médias das duas amostras,

* S<sup>2</sup><sub>p</sub> = desvio padrão das amostras,

* *n* = tamanho das amostras.

> ####  Premissas do Teste t : 
> - As amostras devem ser independentes;
> - As unidades amostrais são selecionadas aleatoriamente;
> - Distribuição normal (gaussiana) dos resíduos. **Observação:** Zar (2010, p. 136) indica que o Test T é robusto mesmo com moderada violação da normalidade, principalmente se o tamanho amostral for alto.
> - Homogeneidade da variância. **Observação.** Caso as variâncias não sejam homogêneas, isso deve ser informado na linha de comando, pois o denominador da fórmula acima será corrigido.

<p>&nbsp;</p>

#### Exemplo prático 1 - Teste T para duas amostras com variâncias iguais
##### Explicação dos dados

Neste exemplo avaliaremos o comprimento rostro-cloacal (CRC em milímetros) de machos de *Physalaemus natteri* (Anura:Leptodactylidae) amostrados em diferentes estações do ano com armadilhas de interceptação e queda na região noroeste do estado de São Paulo  (da Silva & Rossa-Feres 2010). 

**Pergunta:** 

> O CRC dos machos de *P. nattereri* é maior na estação chuvosa do que na estação seca?

**Predições**

> O CRC dos machos será maior na estação chuvosa porque há uma vantangem seletiva para os indivíduos maiores durante a atividade reprodutiva.
 

**Variáveis**

* Variáveis preditoras
  + Dataframe com os indivíduos (unidade amostral) nas linhas e CRC (mm - variável resposta contínua) e estação (variável preditora categórica) como colunas.
  

**Checklist**

* Verificar se o seu dataframe está com as unidades amostrais nas linhas e variáveis preditores nas colunas


### Análise

Calculo do Teste T para duas amostras independentes com variâncias iguais

```{r}

## IMPORTANDO OS DADOS
#************************
CRC_PN_macho <- ecodados::teste_t_var_igual
# verificar se o dataframe foi lido corretamente e se não há erros
# Esses comandos são úteis para planilhas grandes
head(CRC_PN_macho) # mostra as seis primeiras linhas da planilha
tail(CRC_PN_macho) # mostra as seis últimas linhas da planilha

# TESTE NORMALIDADE
#************************
## Verificando normalidade usando QQ-plot
## Os pontos não podem fugir da reta criando formas como U
residuos <- lm(CRC ~ Estacao, data = CRC_PN_macho)
library("car")
qqPlot(residuos)

## Outra possibilidade é usar o teste de Shapiro-Wilk para verificar normalidade
## Hipótese nula que a distribuição é normal 
## valor de p < 0.05 significa que os dados não apresentam distribuição normal
## valor de p > 0.05 significa que os dados apresentam distribuição normal
shapiro.test (CRC_PN_macho$CRC) 

# TESTE DE HOMOGENEIDADE DA VARIÂNCIA
#***************************************
## Hipótese nula que a variância é homogênea
## valor de p < 0.05 significa que os dados não apresentam homogeneidade
## valor de p > 0.05 significa que os dados apresentam homogeneidade
library(car)
leveneTest(CRC ~ Estacao, data = CRC_PN_macho)


# TESTE T AMOSTRAS INDEPENDENTES E VARIÂNCIAS IGUAIS
#******************************************************888
t.test(CRC ~ Estacao, data = CRC_PN_macho, var.equal = TRUE)

```


Visualizar os resultados em gráfico 

```{r}
library(ggplot2)
ggplot(data = CRC_PN_macho, aes(x= Estacao, y= CRC, color = Estacao)) + 
  labs(x = "Estações", y = "CRC (mm) - P. nattereri", size = 15) +
  geom_boxplot(fill=c("steelblue1", "springgreen1"), color="black", outlier.shape = NA) +
  geom_jitter(shape = 16, position=position_jitter(0.1), cex = 6, alpha = 0.7) +
  scale_color_manual(values = c("black", "black")) +
  geom_text(x = 2.2, y = 4.6, label = "t = 4.15, P < 0.001", color = "black", size = 5) +
  theme_bw() +
  theme(axis.text.y = element_text(size = 15), axis.text.x = element_text(size = 15)) +
  theme(axis.title.y = element_text(size = 15), axis.title.x = element_text(size = 15)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  theme(legend.position = "none")
```


**Interpretação dos resultados**

Neste exemplo, rejeitamos a hipótese nula que as médias do CRC dos machos entre as estações seca e chuvosa são iguais (t = 4,15, P < 0,001). Os resultados mostram que os machos de *P. nattereri* coletados na estação chuvosa foram em média 0,43mm maiores do que os coletados na estação seca.

<p>&nbsp;</p>

#### Exemplo prático 2 - Teste T para duas amostras independentes com variâncias diferentes
##### Explicação dos dados

Neste exemplo, avaliaremos o comprimento rostro-cloacal (CRC - milímetros) de fêmeas de *Leptodactylus podicipinus*  amostradas em diferentes estações do ano com armadilhas de interceptação e queda na região noroeste do estado de São Paulo  (da Silva & Rossa-Feres 2010). **Observação:** Os dados foram alterados em relação a publicação original para se enquadrarem no exemplo de amostras com variâncias diferentes.  

**Pergunta:** 

> O CRC das fêmeas de *L. podicipinus* é maior na estação chuvosa do que na estação seca?

**Predições**

> O CRC das fêmeas será maior na estação chuvosa porque há uma vantangem seletiva para os indivíduos maiores durante a atividade reprodutiva.
 

**Variáveis**

* Variáveis preditoras
  + Dataframe com os indivíduos (unidade amostral) nas linhas e CRC (mm - variável resposta contínua) e estação (variável preditora categórica) como colunas.
  

**Checklist**

* Verificar se o seu dataframe está com as unidades amostrais nas linhas e variáveis preditores nas colunas


### Análise

Calculo do Teste T para duas amostras com variâncias diferentes

```{r}
## IMPORTANDO OS DADOS
#*************************
CRC_LP_femea <- ecodados::teste_t_var_diferente
head(CRC_LP_femea) # verificar se o dataframe foi lido corretamente

# TESTE NORMALIDADE
#************************
## Verificando normalidade usando QQ-plot
## Os pontos não podem fugir da reta criando formas como U
residuos_LP <- lm(CRC ~ Estacao, data = CRC_LP_femea)
library("car")
qqPlot(residuos_LP)

## Outra possibilidade é usar o teste de Shapiro-Wilk para verificar normalidade
## Hipótese nula que a distribuição é normal 
## valor de p < 0.05 significa que os dados não apresentam distribuição normal
## valor de p > 0.05 significa que os dados apresentam distribuição normal
shapiro.test (CRC_LP_femea$CRC) 


# TESTE DE HOMOGENEIDADE DA VARIÂNCIA
#***************************************
## Hipótese nula que a variância é homogênea
## valor de p < 0.05 significa que os dados não apresentam homogeneidade
## valor de p > 0.05 significa que os dados apresentam homogeneidade
library(car)
leveneTest(CRC ~ Estacao, data = CRC_LP_femea)


# TESTE T COM AMOSTRAS INDEPENDENTES E VARIÂNCIS DIFERENTES
#***********************************************************
## Com base no teste de Levene, avise na linha de comando que as variâncias 
## não são iguais (var.equal = FALSE).
t.test(CRC ~ Estacao, data = CRC_LP_femea, var.equal = FALSE)

```


Visualizar os resultados em gráfico 

```{r}
library(ggplot2)
ggplot(data = CRC_LP_femea, aes(x= Estacao, y= CRC, color = Estacao)) + 
  labs(x = "Estações", y = "CRC (mm) - L. podicipinus", size = 15) +
  geom_boxplot(fill=c("steelblue1", "springgreen1"), color="black", outlier.shape = NA) +
  geom_jitter(shape = 16, position=position_jitter(0.1), cex = 6, alpha = 0.7) +
  scale_color_manual(values = c("black", "black")) +
  geom_text(x = 2.2, y = 1.7, label = "t = 1.76, P = 0.12", color = "black", size = 5) +
  theme_bw() +
  theme(axis.text.y = element_text(size = 15), axis.text.x = element_text(size = 15)) +
  theme(axis.title.y = element_text(size = 15), axis.title.x = element_text(size = 15)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  theme(legend.position = "none")
```


**Interpretação dos resultados**

Neste exemplo, não rejeitamos a hipótese nula e consideramos que as médias do CRC das fêmeas entre as estações seca e chuvosa são iguais (t = 1,76, P = 0,12). Os resultados mostram que as fêmeas de *L. podicipinus* coletadas na estação chuvosa não são maiores do que as fêmeas coletadas na estação seca.

<p>&nbsp;</p>

## Teste T para amostras pareadas

### Background da análise

O Teste T Pareado é uma estatística que  usa dados medidos duas vezes na mesma unidade amostral, resultando em pares de observações para cada amostra (amostras pareadas). Ele determina se a diferença da média entre duas observações é zero. 

> $$ t = \frac{\bar{d}}{S_{\bar{d}}}$$

Onde: 

* $\bar{d}$ = média da diferença das medidas pareadas. Observe que o teste não usa as medidas originais, e sim, a diferença para cada par,

* S<sub>$\bar{d}$</sub> = erro padrão da diferença das medidas pareadas.


> ####  Premissas do Teste t para amostras pareadas: 
> - As unidades amostrais são selecionadas aleatoriamente;
> - Distribuição normal (gaussiana) dos valores da diferença para cada par;

<p>&nbsp;</p>

#### Exemplo prático 1 - Teste T para amostras pareadas
##### Explicação dos dados

Neste exemplo avaliaremos a diferença na riqueza de espécies de artrópodes registradas em 27 localidades. Todas as localidades foram amostradas duas vezes. A primeira amostragem foi realizada com na localidade antes da pertubação e a segunda amostragem foi realizada após a localidade ter sofrido uma queimada.  

**Pergunta:** 

> A riqueza de espécies de artrópodes é prejudicada pelas queimadas? 

**Predições**

> A riqueza de espécies de artrópodes será maior antes da queimada devido a extinção local das espécies.
 

**Variáveis**

* Variáveis preditoras
  + Dataframe com as localidades nas linhas e riqueza de espécies (variável preditora contínua) e estado (Pre-queimada ou Pós-queimada - variável categórica) da localidade nas colunas.
  

**Checklist**

* Verificar se o seu dataframe está com as unidades amostrais nas linhas e variáveis preditores nas colunas


### Análise

Calculo do Teste T com amostras pareadas

```{r}
## IMPORTANDO OS DADOS
#*************************
Pareado <- ecodados::teste_t_pareado
head(Pareado) # verificar se o dataframe foi lido corretamente
tail(Pareado)

# TESTE T PAREADO
#*****************
# O uso do [] é para selecionar dentro do vetor/coluna *Riqueza* os 27 primeiros números [1:27] que representam as localidades antes da queimada e os últimos 27 números [28:54] que representam as mesmas localidades pós-queimada
t.test(Pareado$Riqueza[1:27], Pareado$Riqueza[28:54], paired = TRUE)

```


Visualizar os resultados em gráfico 

```{r}
library("ggpubr")
ggpaired(Pareado, x = "Estado", y = "Riqueza",
         color = "Estado", line.color = "gray", line.size = 0.8, palette = "jco", width = 0.8,
         point.size = 3, xlab = "Estado das localidades", ylab = "Riqueza de Espécies") +
  expand_limits(y=c(0,150)) 
```


**Interpretação dos resultados**

Neste exemplo, rejeitamos a hipótese nula que a riqueza de espécies de artrópodes é igual antes e depois da queimada (t = 7,57, P < 0,001). Os resultados mostram que as localidades após as queimadas apresentam em média 44,5 espécies de artrópodes a menos do que antes das queimadas.

<p>&nbsp;</p>

## Correlação de Pearson

### Background da análise

É um teste que mede a o grau de associação entre duas variáveis contínuas (X e Y). Importante ressaltar que a análise de correlação não assume que a variável X influêncie a variável Y ou que exista uma relação de causa e efeito entre elas (Zar 2016). A análise é definida em termos da variância de X, a variância de Y, e a covariância de X e Y (i.e. como elas variam juntas).

> $$ r = \frac{\sum{XY} - \frac{\sum{X} \sum{Y}}{n}}{\sqrt{\left(\sum{X^2} - \frac{\sum{X}^2}{n}\right)\left(\sum{Y^2} - \frac{\sum{Y}^2}{n}\right)}} $$

Onde: 

* r = coeficiente de correlação que indica a força da relação entre as duas variáveis. Seu range de valores está entre -1 $\leq$ r $\geq$ 1. A correlação positiva indica que o aumento no valor de uma das variáveis é acompanhado pelo aumento no valor da outra variável. A correlação negativa indica que um aumento no valor de uma das variáveis é acompanhado pela diminuição no valor da outra variável. Se *r* é igual a zero, não existe correlação entre as variáveis.

> ####  Premissas da Correlação de Person: 
> - As amostras devem ser independentes e pareadas (i.e. as duas variáveis devem ser medidas na mesma unidade amostral);
> - As unidades amostrais são selecionadas aleatoriamente;
> - A relação entre as variáveis tem que ser linear.

<p>&nbsp;</p>

#### Exemplo prático 1 - Correlação de Pearson
##### Explicação dos dados

Neste exemplo avaliaremos a correlação entre a altura do tronco e o tamanho da raiz medidos em 35 indivíduos de uma espécie vegetal arbustiva.

**Pergunta:** 

> Existe correlação entre a altura do tronco e o tamanho da raiz dos arbustos?

**Predições**

> A altura do tronco é positivamente correlacionado com o tamanho da raiz.
 

**Variáveis**

* Variáveis preditoras
  + Dataframe com os indivíduos (unidade amostral) nas linhas e altura do tronco e tamanho da raiz (duas variáveis tem que ser contínuas) como colunas.
  

**Checklist**

* Verificar se o seu dataframe está com as unidades amostrais nas linhas e variáveis preditores nas colunas


### Análise

Calculo do Teste de Correlação de Pearson

```{r}
## IMPORTANDO OS DADOS
#************************
correlacao_arbustos <- ecodados::correlacao
head(correlacao_arbustos) # verificar se o dataframe foi lido corretamente

# Teste de Correlação de Pearson
#********************************
# Para outros testes de correlação como Kendall ou Spearman é só alterar na linha de comando a opção *method* e inserir o teste desejado.
cor.test(correlacao_arbustos$Tamanho_raiz, correlacao_arbustos$Tamanho_tronco, method = "pearson")

```


Visualizar os resultados em gráfico 

```{r}
library(ggplot2)
ggplot(data = correlacao_arbustos, aes(x= Tamanho_raiz, y= Tamanho_tronco)) + 
  labs(x = "Tamanho da raiz", y = "Altura do tronco", size = 20) +
  geom_point(size = 10, shape = 21, fill = "gray") +
  geom_text(x = 14, y = 14, label = "r = 0.89, P < 0.001", color = "black", size = 7) +
  theme_bw() +
  theme(axis.title.y = element_text(size = 20), axis.title.x = element_text(size = 20)) +
  theme(axis.text.y = element_text(size = 20), axis.text.x = element_text(size = 20)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.border = element_rect(colour = "black", fill=NA, size = 2)) +
  geom_smooth(method = lm, se = FALSE, color = "black", linetype="dashed") 
```


**Interpretação dos resultados**

Neste exemplo, rejeitamos a hipótese nula que as variáveis não são correlacionadas (r = 0.89, P < 0,001). Os resultados mostram que o aumento na altura dos arbutos é acompanhado pelo aumento no tamanho da raiz.

<p>&nbsp;</p>


## Regressão Linear Simples

### Background da análise

A regressão simples é usada para analisar a relação entre uma variável preditora (plotada no eixo-X) e uma variável resposta (plotada no eixo-Y). As duas variáveis devem ser contínuas. Diferente das correlações, a regressão assume uma relação de causa e efeito entre as variáveis. O valor da variável preditora (X) causa, direta ou indiretamente, o valor da variável resposta (Y). Assim, Y é uma função linear de X:

> $$ Y = \beta_0 + \beta_{1}X_i + \epsilon_i $$

Onde: 

* $\beta_0$ = intercepto que representa o valor da função quando X = 0,

* $\beta_{1}$ = inclinação (*slope*) que mede a mudança na variável Y para cada mudança de unidade da variável X. Este parâmetro é usado para testar a hipótese nula da regressão que assume que $\beta_{1}$ = 0.

* $\epsilon_{1}$ = erro aleatório referente a variável Y que não pode ser explicado pela variável X.

> ####  Premissas da Regressão Linear Simples: 
> - As amostras devem ser independentes;
> - As unidades amostrais são selecionadas aleatoriamente;
> - Distribuição normal (gaussiana) dos resíduos; 
> - Homogeneidade da variância. 

<p>&nbsp;</p>

#### Exemplo prático 1 - Regressão linear simples
##### Explicação dos dados

Neste exemplo, avaliaremos a relação entre o gradiente de temperatura média anual (°C) e o tamanho médio do comprimento rostro-cloacal (CRC em mm) de populações de *Dendropsophus minutus* (Anura:Hylidae) amostradas em 109 localidades no Brasil (Boaratti & da Silva 2015). 

**Pergunta:** 

> Há relação entre o tamanho do CRC das populações e a temperatura das localidades onde os indivíduos ocorrem?

**Predições**

> O CRC das populações serão menores em localidades mais quentes do que em localidades mais frias de acordo com a Hipótese do balanço de calor.
 

**Variáveis**

* Variáveis preditoras
  + Dataframe com as populações (unidade amostral) nas linhas e CRC médio (mm) e temperatura média anual como colunas.
  

**Checklist**

* Verificar se o seu dataframe está com as unidades amostrais nas linhas e variáveis preditores nas colunas


### Análise

Calculo da regressão linear simples

```{r}
## IMPORTANDO DADOS
#********************
dados_regressao <- ecodados::regressoes
head(dados_regressao) # verificar se o dataframe foi lido corretamente

# ANALISE DA REGRESSÃO
#************************
modelo_regressao <- lm(CRC ~ Temperatura, data = dados_regressao)

# PRIMEIRO VAMOS VERIFICAR A NORMALIDADE E HOMOGENEIDADE DAS VARIÂNCIAS
#***********************************************************************
# Os gráficos *Residuals vs Fitted*, *Scale-Location*, e *Residual vs Leverage* estão relacionados com a homogeneidade da variância. Nestes gráficos, esperamos ver os pontos dispersos no espaço sem padrões com formatos em *U* ou funil. 
# O gráfico *Normal Q-Q* está relacionado com a distribuição normal dos resíduos. Neste gráfico, esperamos ver os pontos próximos a reta sem padrões com formatos em *U* ou *S*. 
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(modelo_regressao)
dev.off()

# VERIFICANDO OS RESULTADOS DA REGRESSÃO
#****************************************
anova(modelo_regressao)

# ou
# esta função apresenta os resultados mais detalhados com a estimativa do intercepto, inclinação da reta (slope) e o coeficiente de determinação (R2) que indica a proporção da variação na variável Y que pode ser atribuída à variação na variável X.
summary(modelo_regressao)
```


Visualizar os resultados em gráfico 

```{r}
library(ggplot2)
ggplot(data = dados_regressao, aes(x= Temperatura, y= CRC)) + 
  labs(x = "Temperatura média anual (°C)", y = "Comprimento rostro-cloacal (mm)", size = 20) +
  geom_point(size = 10, shape = 21, fill = "gray") +
  geom_text(x = 25, y = 17.8, label = "R2 = 0.26, P < 0.001", color = "black", size = 7) +
  theme_bw() +
  theme(axis.title.y = element_text(size = 20), axis.title.x = element_text(size = 20)) +
  theme(axis.text.y = element_text(size = 20), axis.text.x = element_text(size = 20)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.border = element_rect(colour = "black", fill=NA, size = 2)) +
  geom_smooth(method = lm, se = FALSE, color = "black") 
```


**Interpretação dos resultados**

Neste exemplo, rejeitamos a hipótese nula que não existe relação entre o tamanho do CRC das populações de *D. minutus* e a temperatura da localidade onde elas ocorrem (F<sub>1,107</sub> = 38,92, P < 0,001). Os resultados mostram que o tamanho do CRC das populações tem uma relação positiva com a temperatura das localidades. Assim, populações de *D. minutus* em localidades mais quentes apresentam maior CRC do que as populações em localidades mais frias.

<p>&nbsp;</p>

## Regressão Linear Múltipla

### Background da análise

A regressão múltipla é uma extensão da regressão simples. Ela é usada quando queremos determinar o valor da variável resposta (Y) com base nos valores de duas ou mais variáveis preditoras (X<sub>1</sub>, X<sub>2</sub>, X<sub>*n*</sub>). 

> $$ Y = \beta_0 + \beta_{1}X_1 + \beta_{n}X_n + \epsilon_i $$

Onde: 

* $\beta_0$ = intercepto que representa o valor da função quando X = 0;

* $\beta_{n}$ = inclinação (*slope*) que mede a mudança na variável Y para cada mudança de unidade das variáveis X<sub>n</sub>;

* $\epsilon_{1}$ = erro aleatório referente a variável Y que não pode ser explicado pelas variáveis preditoras.

> ####  Premissas da Regressão Linear Múltipla: 
> - As amostras devem ser independentes;
> - As unidades amostrais são selecionadas aleatoriamente;
> - Distribuição normal (gaussiana) dos resíduos; 
> - Homogeneidade da variância. 

<p>&nbsp;</p>

#### Exemplo prático 1 - Regressão linear múltipla
##### Explicação dos dados

Utilizaremos o mesmo exemplo da regressão simples. Contudo, além do gradiente de temperatura média anual (°C) incluiremos o gradiente de precipitação anual (mm) como outra variável preditora do tamanho médio do comprimento rostro-cloacal (CRC em mm) de populações de *Dendropsophus minutus* (Anura:Hylidae) amostradas em 109 localidades no Brasil (Boaratti & da Silva 2015).

**Pergunta:** 

> O tamanho do CRC das populações de *D. minutus* é influênciado pela temperatura e precipitação das localidades onde os indivíduos ocorrem?

**Predições**

> O CRC das populações serão menores em localidades com clima quente e chuvoso do que em localidades com clima frio e seco.
 

**Variáveis**

* Variáveis preditoras
  + Dataframe com as populações (unidade amostral) nas linhas e CRC médio (mm) e temperatura e precipitação como colunas.
  

**Checklist**

* Verificar se o seu dataframe está com as unidades amostrais nas linhas e variáveis preditores nas colunas


### Análise

Cálculo da regressão linear múltipla

```{r}
## IMPORTANDO DADOS
#********************
dados_regressao_mul <- ecodados::regressoes
head(dados_regressao_mul) # verificar se o dataframe foi lido corretamente

# ANALISE DA REGRESSÃO
#************************
modelo_regressao_mul <- lm(CRC ~ Temperatura + Precipitacao, data = dados_regressao_mul)

# MULTICOLINEARIDADE
#********************
# Multicolinearidade ocorre quando as variáveis preditoras são correlacionadas. Essa correlação é um problema porque as variáveis preditores deveriam ser independentes. O Fator de Inflação da Variância (VIF) é um teste que identifica a correlação entre as variáveis e mostra a força dessa correlação. Alguns autores consideram valores de VIF acima de 10 como fortemente correlacionadas, outros mais conservadores consideram o valor de 3.
library(car)
vif(modelo_regressao_mul)

# VERIFICANDO A NORMALIDADE E HOMOGENEIDADE DAS VARIÂNCIAS
#***********************************************************************
# Os gráficos *Residuals vs Fitted*, *Scale-Location*, e *Residual vs Leverage* estão relacionados com a homogeneidade da variância. Nestes gráficos, esperamos ver os pontos dispersos no espaço sem padrões em forma de *U* ou funil. 
# O gráfico *Normal Q-Q* está relacionado com a distribuição normal dos resíduos. Neste gráfico, esperamos ver os pontos próximos a reta sem padrões em forma de *U* ou *S*. 
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(modelo_regressao_mul)
dev.off()

# VERIFICANDO OS RESULTADOS DA REGRESSÃO
#****************************************
anova(modelo_regressao_mul)

# ou
summary(modelo_regressao_mul)
```

Percebam que a temperatura tem uma relação significativa com o tamanho do CRC das populações (P < 0.001), enquanto que a precipitação não apresenta relação com o CRC (P = 0.27). Neste caso, é interessante saber se um modelo mais simples (e.g. contendo apenas temperatura) explicaria a distribuição tão bem ou melhor do que este modelo mais complexo considerando dois parâmetros (temperatura e precipitação). 

Para isso, podemos utilizar a *LIKELIHOOD RATIO TEST (LRT)* para comparar modelos. A LRT compara dois modelos aninhados, testando se os parâmetros do modelo mais complexo diferem significativamente do modelo mais simples.Em outras palavras, ele testa se há necessidade de se incluir um parâmetro extra no modelo para explicar os dados.

```{r}
## CRIANDO OS MODELOS ANINHADOS
#********************************
modelo_regressao_mul <- lm(CRC ~ Temperatura + Precipitacao, data = dados_regressao_mul)
modelo_regressao <- lm(CRC ~ Temperatura, data = dados_regressao_mul)

# LIKELIHHOD RATIO TEST (LRT)
#*******************************
# A hipótese nula é que o modelo mais simples é melhor
# Valores de p < 0.05 rejeita a hipótese nula e o modelo mais complexo é o melhor
# Valores de p > 0.05 não rejeita a hipótese nula e o modelo mais simples é o melhor
library(lmtest)
lrtest(modelo_regressao_mul, modelo_regressao)


# COMPARANDO COM O MODELO SOMENTE COM O INTERCEPTO
#************************************************
# criando um modelo sem parâmetros, só o intercepto
modelo_intercepto <- lm(CRC ~ 1, data = dados_regressao_mul)
lrtest(modelo_regressao, modelo_intercepto)
```

**Interpretação dos resultados**

Neste exemplo, a precipitação não está associada com a variação no tamanho do CRC das populações de *D. minutus*. Por outro lado, temperatura explicou 26% da variação do tamanho do CRC das populações. 

<p>&nbsp;</p>

## Análises de Variância (ANOVA)

### Background da análise

Anova refere-se a uma variedade de delineamentos experimentais nos quais a variável preditora é categórica e a variável resposta é contínua (Gotelli & Ellison 2013). Exemplos desses delineamentos experimentais são: Anova de um fator, Anova de dois fatores, Anova em blocos aleatorizados, Anova de medidas repetidas e Anova *split-splot*. De forma geral, a Anova é um teste estatístico usado para comparar a média entre grupos amostrados independentementes. Para isso,  o teste leva em conta, além das médias dos grupos, a variação dos dados dentro e entre os grupos. Neste capítulo, iremos demonstrar as linhas de comandos para alguns dos principais delineamentos experimentais. 

> ####  Premissas da Anova: 
> - As amostras devem ser independentes;
> - As unidades amostrais são selecionadas aleatoriamente;
> - Distribuição normal (gaussiana) dos resíduos; 
> - Homogeneidade da variância. 

<p>&nbsp;</p>

## ANOVA de um fator
Este teste considera delineamentos experimentais com apenas um fator (ou tratamento) que pode ser composto por três ou mais grupos (ou níveis).  

#### Exemplo prático 1 - Anova de um fator
##### Explicação dos dados

Neste exemplo, avaliaremos se o adubo X-2020 disponibilizado recentemente no mercado melhora o crescimento dos indivíduos de *Coffea arabica* como divulgado pela empresa responsável pela venda do produto. Para isso, foi realizado um experimento com indivíduos de *C. arabica* cultivados em três grupos: i) grupo controle onde os indivíduos não receberam adubação, ii) grupo onde os indivíduos receberam a adição do adubo tradicional mais utilizado pelos produtores de *C. arabica*, e iii) grupo onde os indivíduos receberam a adição do adubo X-2020.

**Pergunta:** 

> O crescimento dos indivíduos de *C. arabica* é melhorado pela adição do adubo X-2020?

**Predições**

> O crescimento dos indivíduos de *C. arabica* será maior no grupo que recebeu o adubo X-2020.
 

**Variáveis**

* Variáveis preditoras
  + Dataframe com as plantas (unidade amostral) nas linhas e o tratamento na coluna.
  

**Checklist**

* Verificar se o seu dataframe está com as unidades amostrais nas linhas e variável preditora na coluna.


### Análise

Cálculo da Anova de um fator

```{r}
## IMPORTANDO DADOS
#********************
dados_anova_simples <- ecodados::anova_simples
head(dados_anova_simples) # verificar se o dataframe foi lido corretamente

# ANALISE ANOVA de um fator
#************************
Modelo_anova <- aov(Crescimento ~ Tratamento, data = dados_anova_simples) 

# VERIFICANDO A NORMALIDADE E HOMOGENEIDADE DAS VARIÂNCIAS
#***********************************************************************
# Os gráficos *Residuals vs Fitted* e *Scale-Location* estão relacionados com a homogeneidade da variância. Nestes gráficos, esperamos ver os pontos dispersos no espaço sem padrões em forma de *U* ou funil. 
# O gráfico *Normal Q-Q* está relacionado com a distribuição normal dos resíduos. Neste gráfico, esperamos ver os pontos próximos a reta sem padrões em forma de *U* ou *S*. 
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(Modelo_anova)
dev.off()

# Se preferir, você pode utilizar testes estatísticos
# Teste de Shapiro-Wilk para normalidade separadamente para cada grupo
shapiro.test(dados_anova_simples$Crescimento[1:12])
shapiro.test(dados_anova_simples$Crescimento[13:24])
shapiro.test(dados_anova_simples$Crescimento[25:36])

# Teste de Bartlett para homogeneidade da variância
bartlett.test(Crescimento ~ Tratamento, data = dados_anova_simples)


# VERIFICANDO OS RESULTADOS DA ANOVA
#****************************************
anova(Modelo_anova)
```

Percebam que o resultado da Anova (Pr(>F) < 0.001) indica que devemos rejeitar a hipótese nula que não há diferença entre as médias dos grupos. Contudo, os resultados não mostram quais são os grupos que apresentam diferenças. Para isso, temos que realizar testes de comparações múltiplas *post-hoc* para detectar os grupos que apresentam diferenças significativas entre as médias. **Observação** Os testes *post-hoc* só devem ser utilizados quando rejeitamos a hipótese nula (P < 0.05) no teste da Anova.

```{r}
# Diferenças entre os tratamentos
#***********************************
# Teste de Tuckey's honest significant difference
TukeyHSD(Modelo_anova)
```

Visualizar os resultados em gráfico 

```{r}
# Reordenando a ordem que os grupos irão aparecer no gráfico
dados_anova_simples$Tratamento <- factor(dados_anova_simples$Tratamento , 
                                      levels=c("Controle", "Adubo_Tradicional", "Adubo_X-2020"))

# Gráfico
library(ggplot2)
ggplot(data = dados_anova_simples, aes(x= Tratamento, y= Crescimento, color = Tratamento)) + 
  labs(x = "Adubação", y = "Crescimento Coffea arabica (cm)", size = 20) +
  geom_boxplot(fill=c("steelblue1", "springgreen1", "brown1"), color="black", show.legend = FALSE,
               alpha = 0.4) +
  geom_jitter(shape = 16, position=position_jitter(0.1), cex = 4, alpha = 0.7) +
  scale_color_manual(values = c("steelblue1", "springgreen1", "brown1")) +
  scale_y_continuous(limits = c(0, 20), breaks = c(0, 5, 10, 15, 20)) +
  geom_text(x = 1, y = 12, label = "ab", color = "black", size = 5) +
  geom_text(x = 2, y = 17, label = "a", color = "black", size = 5) +
  geom_text(x = 3, y = 17, label = "b", color = "black", size = 5) +
  scale_x_discrete(labels=c("Sem adubo","Tradicional","X-2020")) +
  theme_bw() +
  theme(axis.title.y = element_text(size = 17), axis.title.x = element_text(size = 17)) +
  theme(axis.text.y = element_text(size = 17), axis.text.x = element_text(size = 17)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.border = element_rect(colour = "black", fill=NA, size = 2)) +
  theme(legend.position = "none") 
```


**Interpretação dos resultados**

Neste exemplo, os indivíduos de *C. arabica* que receberam adubação (tradicional e X-2020) apresentaram maior crescimento do que os indivíduos que não receberam adubação. Contudo, diferente do que foi divulgado pela empresa, o adubo X-2020 não apresentou melhor desempenho que o adubo tradicional já utilizado pelos produtores.

<p>&nbsp;</p>

## ANOVA de dois fatores ou Anova fatorial
Este teste considera delineamentos amostrais com dois fatores (ou tratamento) que podem ser compostos por dois ou mais grupos (ou níveis). Esta análise tem uma vantagem, pois permite avaliar o efeito da interação entre os fatores na variável resposta. Quando a interação está presente, o impacto de um fator depende do nível (ou grupo) do outro fator. 

#### Exemplo prático 1 - Anova de dois fatores
##### Explicação dos dados

Neste exemplo, avaliaremos se o tempo que o corpo leva para elimiar uma droga utilizada em exames de ressonância magnética está relacionado com o sistema XY de determinação do sexo e/ou com a idade dos pacientes. Para isso, foi realizado um experimento com 40 pacientes distribuídos da seguinte maneira: i) 10 indivíduos XX - jovens, ii) 10 indivíduos XX - idosas,  iii) 10 indivíduos XY - jovens, e iv) 10 indivíduos XY - idosos.

**Pergunta:** 

> O tempo de eliminação da droga é dependente do sistema XY de determinação do sexo e idade dos pacientes?

**Predições**

> O tempo de eliminação da droga vai ser mais rápido nas pacientes XX e jovens.
 

**Variáveis**

* Variáveis preditoras
  + Dataframe com os pacientes (unidade amostral) nas linhas e os tratamentos nas colunas.
  

**Checklist**

* Verificar se o seu dataframe está com as unidades amostrais nas linhas e as variáveies preditoras nas colunas.


### Análise

Cálculo da Anova de dois fator

```{r}
## IMPORTANDO DADOS
#********************
dados_dois_fatores <- ecodados::anova_dois_fatores
head(dados_dois_fatores) 

# Análise anova de dois fatores 
#********************************
# A interação entre os fatores é representada por *
Modelo1 <- aov(Tempo ~ Pessoas * Idade, data = dados_dois_fatores) 

# Olhando os resultados
anova(Modelo1)

# Percebam que a interação não apresenta um efeito significativo (P > 0.05). Assim, iremos retirar a interação e verificar, usando LIKELIHOOD RATIO TEST (LRT), se o modelo mais simples é melhor 
Modelo2 <- aov(Tempo ~ Pessoas + Idade, data = dados_dois_fatores) 

# A hipótese nula é que o modelo mais simples é melhor
# Valores de p < 0.05 rejeita a hipótese nula e o modelo mais complexo é o melhor
# Valores de p > 0.05 não rejeita a hipótese nula e o modelo mais simples é o melhor
library(lmtest)
lrtest(Modelo1, Modelo2)

# VERIFICANDO A NORMALIDADE E HOMOGENEIDADE DAS VARIÂNCIAS
#***********************************************************************
# Esta função mostra os resultados para multicolinearidade (a), dois gráficos avaliando a normalidade dos resíduos (b e  c), e um gráfico para a homogeneidade dos resíduos (d).
library(sjPlot)
plot_grid(plot_model(Modelo2, type = "diag"))

# VERIFICANDO OS RESULTADOS DA ANOVA
#****************************************
anova(Modelo2)
```

Percebam que o resultado da Anova (Pr(>F) < 0.001) indica que devemos rejeitar a hipótese nula que não há diferença entre as médias dos sistema XY e idade dos pacientes. Neste caso, não precisamos realizar testes de comparações múltiplas *post-hoc* porque os fatores apresentam apenas dois níveis. Contudo, se no seu delineamento experimental um dos fatores apresentar três ou mais níveis, você deverá utilizar os testes de comparações *post-hoc* para determinar as diferenças entre os grupos. **Observação** Os testes *post-hoc* só devem ser utilizados quando rejeitamos a hipótese nula (P < 0.05) no teste da Anova.

```{r}
# Diferenças entre os tratamentos
#***********************************
# Teste de Tuckey's honest significant difference
TukeyHSD(Modelo2)
```

Visualizar os resultados em gráfico 

```{r}
# Gráfico
library(ggplot2)
ggplot(data = dados_dois_fatores, aes(y= Tempo, x= Pessoas, color = Idade)) + 
  geom_boxplot() +
  labs(x = "Sistema XY de determinação do sexo", y = "Tempo (horas) para eliminar a droga", 
       size = 20) +
  geom_jitter(shape = 16, position=position_jitterdodge(), cex = 4, alpha = 0.7) +
  scale_color_manual(values = c("steelblue1", "springgreen1")) +
  scale_y_continuous(limits = c(10, 50), breaks = c(10, 20, 30, 40, 50)) +
  theme(axis.title.y = element_text(size = 17), axis.title.x = element_text(size = 17)) +
  theme(axis.text.y = element_text(size = 17), axis.text.x = element_text(size = 17)) +
  theme(panel.grid.minor = element_blank(), 
        panel.border = element_rect(colour = "black", fill=NA, size = 2)) 
```


**Interpretação dos resultados**

Neste exemplo, O sitesma XY de determinação do sexo e a idade dos pacientes tem um efeito no tempo de eliminação da droga do organismo. Os pacientes XX e jovens apresentam eliminação mais rápida da droga do que pacientes XY e idosos.

<p>&nbsp;</p>


#### Exemplo prático 2 - Anova de dois fatores com efeito da interação
##### Explicação dos dados

Neste exemplo usaremos os mesmos dados do exemplo anterior. Neste caso, alteremos os dados para que a interação seja significativa.

```{r}
## IMPORTANDO DADOS
#********************
dados_dois_fatores_interacao <- ecodados::anova_dois_fatores_interacao1
head(dados_dois_fatores_interacao)

# Análise anova de dois fatores 
#********************************
# A interação entre os fatores é representada por *
Modelo_interacao1 <- aov(Tempo ~ Pessoas * Idade, data = dados_dois_fatores_interacao) 

# Olhando os resultados
anova(Modelo_interacao1)
```

Percebam que a interação é significativa (P < 0.05). Agora nossa interpretação precisa ser baseada na interação entre os fatores. Vamos visualizar os resultados em gráfico.

```{r}
# Gráfico
library(ggplot2)
library(ggforce)
ggplot(data = dados_dois_fatores_interacao, aes(y= Tempo, x= Pessoas, color = Idade)) + 
  geom_boxplot() +
  stat_summary(fun = mean, geom="point", aes(group=Idade, x = Pessoas), color = "black",
               position = position_dodge(0.7), size  = 4) +
  geom_link(aes(x = 0.8, y = 31, xend = 1.8, yend = 40), color = "steelblue1", 
            lwd  = 1.3, linetype = 2) + 
  geom_link(aes(x = 1.2, y = 28.5, xend = 2.2, yend = 26.5), color = "springgreen1", 
            lwd  = 1.3, linetype = 2) + 
  labs(x = "Sistema XY de determinação do sexo", y = "Tempo (horas) para eliminar a droga", 
       size = 20) +
  scale_color_manual(values = c("steelblue1", "springgreen1", "steelblue1", 
                                "springgreen1")) +
  scale_y_continuous(limits = c(10, 50), breaks = c(10, 20, 30, 40, 50)) +
  theme(axis.title.y = element_text(size = 17), axis.title.x = element_text(size = 17)) +
  theme(axis.text.y = element_text(size = 17), axis.text.x = element_text(size = 17)) +
  theme(panel.grid.minor = element_blank(), 
        panel.border = element_rect(colour = "black", fill=NA, size = 2))
```

**Interpretação dos resultados**

Percebam que para saber a resposta do fator idade (jovem ou idoso) na eliminação da droga, você precisa saber com qual pessoa (XX ou XY) ele está associado. Isso porque a resposta de um fator depende do outro fator. Jovens eliminam o droga do corpo mais rápido nas pessoa XY enquanto os idosos eliminam a droga mais rápido nas pessoas XX. 

<p>&nbsp;</p>

#### Exemplo prático 3 - Anova de dois fatores com efeito da interação
##### Explicação dos dados

Neste exemplo usaremos os mesmos dados do exemplo anterior. Neste caso, alteremos os dados para que a interação seja significativa.

```{r}
## IMPORTANDO DADOS
#********************
dados_dois_fatores_interacao2 <- ecodados::anova_dois_fatores_interacao2
head(dados_dois_fatores_interacao2)

# Análise anova de dois fatores 
#********************************
# A interação entre os fatores é representada por *
Modelo_interacao2 <- aov(Tempo ~ Pessoas * Idade, data = dados_dois_fatores_interacao2)

# Olhando os resultados
anova(Modelo_interacao2)
```

Percebam que a interação é significativa (P < 0.05), mas a idade não é significativa. Nossa interpretação precisa ser baseada na interação entre os fatores. Vamos visualizar os resultados em gráfico.

```{r}
# Gráfico
library(ggplot2)
library(ggforce)
ggplot(data = dados_dois_fatores_interacao2, aes(y= Tempo, x= Pessoas, color = Idade)) + 
  geom_boxplot() +
  stat_summary(fun = mean, geom="point", aes(group=Idade, x = Pessoas), color = "black",
               position = position_dodge(0.7), size  = 4) +
  geom_link(aes(x = 0.8, y = 31, xend = 1.8, yend = 27), color = "steelblue1", 
            lwd  = 1.3, linetype = 2) + 
  geom_link(aes(x = 1.2, y = 19, xend = 2.2, yend = 41), color = "springgreen1", 
            lwd  = 1.3, linetype = 2) + 
  labs(x = "Sistema XY de determinação do sexo", y = "Tempo (horas) para eliminar a droga", 
       size = 20) +
  scale_color_manual(values = c("steelblue1", "springgreen1", "steelblue1", "springgreen1")) +
  scale_y_continuous(limits = c(10, 50), breaks = c(10, 20, 30, 40, 50)) +
  theme(axis.title.y = element_text(size = 17), axis.title.x = element_text(size = 17)) +
  theme(axis.text.y = element_text(size = 17), axis.text.x = element_text(size = 17)) +
  theme(panel.grid.minor = element_blank(), 
        panel.border = element_rect(colour = "black", fill=NA, size = 2))
```

**Interpretação dos resultados**

Percebam que as linhas se cruzam. Esse é exemplo clássico de interação. Novamente, para saber a resposta do fator idade (jovem ou idoso), você precisa saber com qual pessoa (XX ou XY) ele está associado. Jovens são mais rápidos para eliminar a droga em pessoas XX enquanto os idosos são mais rápidos para eliminar a droga nas pessoas XY.

<p>&nbsp;</p>



## ANOVA em blocos aleatorizados
No delineamento experimental com blocos aleatorizados, cada fator é agrupado em blocos, com réplicas de cada nível do fator representado em cada bloco (Gotelli & Elisson 2013). O bloco é uma área ou período de tempo dentro do qual as condições ambientais são relativamente homogêneas.  O objetivo do uso dos blocos é controlar fontes de variações indesejadas na variável dependente que não são de interesse do pesquisador. Desta maneira, podemos retirar dos resíduos, os efeitos das variações indesejadas que não são do nosso interesse, e testar com maior poder estatístico os efeitos dos tratamentos de interesse. Importante, os blocos devem ser arranjados de forma que as condições ambientais sejam mais similares dentro dos blocos do que entre os blocos. 

<p>&nbsp;</p>

#### Exemplo prático 1 - Anova em blocos aleatorizados
##### Explicação dos dados

Neste exemplo, avaliaremos a riqueza de espécies de anuros amostradas em poças artificiais instaladas a diferentes distâncias de seis fragmentos florestais no sudeste do Brasil (da Silva et al. 2020). Os fragmentos florestais apresentam diferenças entre si que não do interesse do pesquisador. Por isso, eles foram incluídos como blocos nas análises. As poças artificiais foram instaladas em todos os fragmentos florestais basedo no seguinte delineamento experimental (da Silva et al. 2012): i) 4 poças no interior do fragmento a 100m de distância da borda do fragmento; ii) 4 poças no interior no fragmento a 50m de distância da borda do fragmento;  iii) 4 poças no na borda do fragmento;  iv) 4 poças na matriz de pastagem a 50m de distância da borda do fragmento;  e v) 4 poças na matriz de pastagem a 100m de distância da borda do fragmento. Percebam que todos os tratamentos foram instalados em todos os blocos.   


**Pergunta:** 

> A distância da poça artifical ao fragmento florestal influência a riqueza de espécies anuros?

**Predições**

> Poças na borda do fragmento florestal apresentarão maior riqueza de espécies do que poças distantes da borda.
 

**Variáveis**

* Variáveis preditoras
  + Dataframe com as poças (unidade amostral) nas linhas e o tratamento e bloco nas colunas.
  

**Checklist**

* Verificar se o seu dataframe está com as unidades amostrais nas linhas e variáveis preditoras nas colunas.


### Análise

Cálculo da Anova em blocos aleatorizados

```{r}
## IMPORTANDO DADOS
#********************
dados_bloco <- ecodados::anova_bloco
str(dados_bloco) # verificar se o dataframe foi lido corretamente


# ANALISE ANOVA em blocos aleatorizados
#****************************************
# Há duas maneiras para incluir os efeitos dos blocos
model_bloco1 <- aov(Riqueza ~ Pocas + Blocos, data = dados_bloco)

model_bloco2 <- aov(Riqueza ~ Pocas + Error(Blocos), data = dados_bloco)

# Percebam que as duas formas apresentam os mesmo resultados para o efeito da distância das poças que é o fator de interesse no estudo. Lembre-se que nos delineamentos experimentais em bloco, o pesquisador não está interessado no efeito do bloco, mas sim controlar a variação associada a ele.
anova(model_bloco1)
summary(model_bloco2)

# O que não pode acontecer é ignorar o efeito do bloco que é incorporado pelos resíduos quando não informado no modelo. Veja abaixo a forma errada de analisar delineamento experimental com blocos.

modelo_errado <- aov(Riqueza ~ Pocas, data = dados_bloco)
anova(modelo_errado)

# VERIFICANDO A NORMALIDADE E HOMOGENEIDADE DAS VARIÂNCIAS
#***********************************************************************
# Os gráficos *Residuals vs Fitted* e *Scale-Location* estão relacionados com a homogeneidade da variância. Nestes gráficos, esperamos ver os pontos dispersos no espaço sem padrões em forma de *U* ou funil. 
# O gráfico *Normal Q-Q* está relacionado com a distribuição normal dos resíduos. Neste gráfico, esperamos ver os pontos próximos a reta sem padrões em forma de *U* ou *S*. 
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(model_bloco1)
dev.off()
```

Percebam que o resultado da Anova (Pr(>F) < 0.001) indica que devemos rejeitar a hipótese nula que não há diferença entre as médias dos grupos. Contudo, os resultados não mostram quais são os grupos que apresentam diferenças. Para isso, temos que realizar testes de comparações múltiplas *post-hoc* para detectar os grupos que apresentam diferenças significativas entre as médias. **Observação** Os testes *post-hoc* só devem ser utilizados quando rejeitamos a hipótese nula (P < 0.05) no teste da Anova.

```{r}
# Diferenças entre os tratamentos
#***********************************
# Teste de Tuckey's honest significant difference
library(emmeans)
pairs(lsmeans(model_bloco1, "Pocas"), adjust = "tukey")
```

Visualizar os resultados em gráfico 

```{r}
# Reordenando a ordem que os grupos irão aparecer no gráfico
dados_bloco$Pocas <- factor(dados_bloco$Pocas, 
                              levels=c("Int-100m", "Int-50m", "Borda", "Mat-50m", "Mat-100m"))

# Gráfico
library(ggplot2)
ggplot(data = dados_bloco, aes(x= Pocas, y= Riqueza)) + 
  labs(x = "Poças artificiais", y = "Riqueza de espécies de anuros", size = 20) +
  geom_boxplot(color="black", show.legend = FALSE,
               alpha = 0.4) +
  geom_jitter(shape = 16, position=position_jitter(0.1), cex = 5, alpha = 0.7) +
  scale_x_discrete(labels=c("-100m","-50m","Borda", "50m", "100m")) +
  theme(axis.title.y = element_text(size = 17), axis.title.x = element_text(size = 17)) +
  theme(axis.text.y = element_text(size = 17), axis.text.x = element_text(size = 17)) +
  theme(panel.border = element_rect(colour = "black", fill=NA, size = 2)) 
```

**Interpretação dos resultados**

Neste exemplo, rejeitamos a hipótese nula que a distância da poças artificiais até as bordas dos fragmentos florestais não influência a riqueza de espécies de anuros. As poças artificiais instaladas nas bordas dos fragmentos florestais apresentaram maior riqueza de espécies do que as poças distantes.

<p>&nbsp;</p>

## Análise de covariância (ANCOVA)
A ANCOVA pode ser compreendida como uma extensão da Anova com a adição de variável contínua (covariável) medida em todas as unidades amostrais (Gotelli & Ellison 2013). A ideia é que a covariável também afete os valores da variável resposta. Não incluir a covariável irá fazer com que a variação não explicada pelo modelo concentre-se nos resíduos. Incluindo a covariável, o tamanho do resíduo é menor, e o teste para avaliar as diferenças nos tratamentos terá mais poder estatístico. 

<p>&nbsp;</p>

#### Exemplo prático 1 - ANCOVA
##### Explicação dos dados

Neste exemplo, avaliaremos o efeito da herbivoria na biomassa dos frutos de uma espécie de árvore na Mata Atlântica. O delineamento experimental permitiu que alguns indivíduos sofressem herbivoria e outros não. Os pesquisadores também mediram o tamanho da raiz dos indíviduos para inseri-la como uma covariável no modelo. 

**Pergunta:** 

> A herbivoria diminiu a biomssa dos frutos?

**Predições**

> Os indivíduos que sofreram herbivoria irão produzir frutos com menor biomassa do que os indivíduos sem herbivoria.
 

**Variáveis**

* Variáveis preditoras
  + Dataframe com as indivíduos da espéci de planta (unidade amostral) nas linhas e o tratamento e a covariável nas colunas.
  

**Checklist**

* Verificar se o seu dataframe está com as unidades amostrais nas linhas e variáveis preditoras nas colunas.


### Análise

Cálculo da ANCOVA

```{r}
## IMPORTANDO DADOS
#********************
dados_ancova <- ecodados::ancova
str(dados_ancova) # verificar se o dataframe foi lido corretamente


# ANALISE ANCOVA
#****************************************
modelo_ancova <- lm(Biomassa ~ Herbivoria + Raiz, data = dados_ancova)

# VERIFICANDO A NORMALIDADE E HOMOGENEIDADE DAS VARIÂNCIAS
#***********************************************************************
# Esta função mostra os resultados para multicolinearidade (a), dois gráficos avaliando a normalidade dos resíduos (b e  c), e um gráfico para a homogeneidade dos resíduos (d).
library(sjPlot)
plot_grid(plot_model(modelo_ancova, type = "diag"))

# OLHANDO OS RESULTADOS
#********************
anova(modelo_ancova)
```

Percebam que o resultado da ANCOVA (Pr(>F) < 0.001) indica que tanto a herbivoria como a o tamanho da raiz (covariável) tem efeitos significativos na biomassa dos frutos. Contudo, a interação entre as variáveis não foi signigicativa. Vamos usar o Likelihood ratio test (LRT) para ver se podemos seguir com um modelo mais simples (sem interação).

```{r}
modelo_ancova <- lm(Biomassa ~ Herbivoria * Raiz, data = dados_ancova)
modelo_ancova2 <- lm(Biomassa ~ Herbivoria + Raiz, data = dados_ancova)

# LRT 
library(lmtest)
# A hipótese nula é que o modelo mais simples é melhor
# Valores de p < 0.05 rejeita a hipótese nula e o modelo mais complexo é o melhor
# Valores de p > 0.05 não rejeita a hipótese nula e o modelo mais simples é o melhor
lrtest(modelo_ancova, modelo_ancova2)
```

Visualizar os resultados em gráfico 

```{r}
# Gráfico
library(ggplot2)
ggplot(data = dados_ancova, aes(x= Raiz, y= Biomassa, fill = Herbivoria)) + 
  labs(x = "Tamanho da raiz (cm)", y = "Biomassa dos frutos (g)", size = 20) +
  geom_point(size = 10, shape = 21) +
  theme(axis.title.y = element_text(size = 17), axis.title.x = element_text(size = 17)) +
  theme(axis.text.y = element_text(size = 17), axis.text.x = element_text(size = 17)) +
  theme(panel.grid.major = element_blank(),  
        panel.border = element_rect(colour = "black", fill=NA, size = 2)) +
  theme(legend.position="bottom") +
  scale_fill_discrete(name = "Herbivoria", labels = c("Com herbivoria", "Sem herbivoria")) +
  geom_smooth(aes(color=Herbivoria), method="lm", show.legend = FALSE)
```


**Interpretação dos resultados**

Neste exemplo, o tamanho da raiz (covariável) tem uma relação positiva com a biomassa dos frutos. Quanto maior o tamanho da raiz, maior a biomassa dos frutos. Usando a ANCOVA e controlando o efeito da covariável, percebemos que a herbivoria também afeta a biomassa dos frutos. Os indivíduos que não sofreram herbivoria produziram frutos com maior biomassa do que os indivíduos com herbivoria. 

<p>&nbsp;</p>


### Para se aprofundar

* Recomendamos aos interessados os livros: i) Zar (2010) Biostatiscal analysis; ii) Gotelli & Ellison (2013) A primer of ecological statistics; e iii) Quinn & Keough (2002) Experimental design and data analysis for biologists.
